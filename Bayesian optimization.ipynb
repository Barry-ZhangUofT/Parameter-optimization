{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8pyfVb5RKiW"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/krasserm/bayesian-machine-learning/blob/master/bayesian_optimization.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3fk1fgLPRKiY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9c26f6-3902-4513-e5ea-9f36e9303f13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-22 19:06:21--  https://raw.githubusercontent.com/krasserm/bayesian-machine-learning/master/bayesian_optimization_util.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1536 (1.5K) [text/plain]\n",
            "Saving to: ‘bayesian_optimization_util.py’\n",
            "\n",
            "\r          bayesian_   0%[                    ]       0  --.-KB/s               \rbayesian_optimizati 100%[===================>]   1.50K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-22 19:06:21 (18.2 MB/s) - ‘bayesian_optimization_util.py’ saved [1536/1536]\n",
            "\n",
            "Collecting scikit-optimize==0.5.2\n",
            "  Downloading scikit_optimize-0.5.2-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.5.2) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.5.2) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize==0.5.2) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->scikit-optimize==0.5.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->scikit-optimize==0.5.2) (3.3.0)\n",
            "Installing collected packages: scikit-optimize\n",
            "Successfully installed scikit-optimize-0.5.2\n",
            "Collecting GPy==1.9.8\n",
            "  Downloading GPy-1.9.8.tar.gz (989 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m989.5/989.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.10/dist-packages (from GPy==1.9.8) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.10/dist-packages (from GPy==1.9.8) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from GPy==1.9.8) (1.16.0)\n",
            "Collecting paramz>=0.9.0 (from GPy==1.9.8)\n",
            "  Downloading paramz-0.9.6-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from paramz>=0.9.0->GPy==1.9.8) (4.4.2)\n",
            "Building wheels for collected packages: GPy\n",
            "  Building wheel for GPy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPy: filename=GPy-1.9.8-cp310-cp310-linux_x86_64.whl size=3451600 sha256=2cce8a6bbe2539685878420ea3005b616e873126751b5d9122aabaf3b39424ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/8e/d4/2b438bbe320e54162451027cf69e14c8effef2b9e0eb3a3e1e\n",
            "Successfully built GPy\n",
            "Installing collected packages: paramz, GPy\n",
            "Successfully installed GPy-1.9.8 paramz-0.9.6\n",
            "Collecting GPyOpt==1.2.1\n",
            "  Downloading GPyOpt-1.2.1.tar.gz (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting xgboost==0.90\n",
            "  Downloading xgboost-0.90-py2.py3-none-manylinux1_x86_64.whl (142.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.8/142.8 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost==0.90) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost==0.90) (1.11.4)\n",
            "Installing collected packages: xgboost\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.0.3\n",
            "    Uninstalling xgboost-2.0.3:\n",
            "      Successfully uninstalled xgboost-2.0.3\n",
            "Successfully installed xgboost-0.90\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Check if notebook is running in Google Colab\n",
        "    import google.colab\n",
        "    # Get additional files from Github\n",
        "    !wget https://raw.githubusercontent.com/krasserm/bayesian-machine-learning/master/bayesian_optimization_util.py\n",
        "    # Install additional dependencies\n",
        "    !pip install scikit-optimize==0.5.2\n",
        "    !pip install GPy==1.9.8\n",
        "    !pip install GPyOpt==1.2.1\n",
        "    !pip install xgboost==0.90\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jEtHn6sHRKia"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "bounds = np.array([[1,4],[15,35]])\n",
        "\n",
        "noise = 0\n",
        "\n",
        "def f(X, noise=noise):\n",
        "    return [-np.sin(3*X[0]) - X[1]**2 + 0.7*X[0]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "081kCSShRKib"
      },
      "source": [
        "The following plot shows the noise-free objective function, the amount of noise by plotting a large number of samples and the two initial samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "i9KNL0hVRKib"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dense grid of points within bounds\n",
        "#X = [np.arange(bounds[:, 0], bounds[:, 1], 0.1).reshape(-1, 1), np.arange(bounds[:, 0], bounds[:, 1], 0.1).reshape(-1, 1)]\n",
        "\n",
        "# Noise-free objective function values at X\n",
        "#Y = f(X,0)\n",
        "\n",
        "# Plot optimization objective with noise level\n",
        "#plt.plot(X, Y, 'y--', lw=2, label='Noise-free objective')\n",
        "#plt.plot(X, f(X,0), 'bx', lw=1, alpha=0.1, label='Noisy samples')\n",
        "#plt.plot(X_init, Y_init, 'kx', mew=3, label='Initial samples')\n",
        "\n",
        "#plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcbVXbeWRKic"
      },
      "source": [
        "Goal is to find the global optimum on the left in a small number of steps. The next step is to implement the acquisition function defined in Equation (2) as `expected_improvement` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "slyVuCwTRKic"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "def expected_improvement(X, X_sample, Y_sample, gpr, xi=0.01):\n",
        "    '''\n",
        "    Computes the EI at points X based on existing samples X_sample\n",
        "    and Y_sample using a Gaussian process surrogate model.\n",
        "\n",
        "    Args:\n",
        "        X: Points at which EI shall be computed (m x d).\n",
        "        X_sample: Sample locations (n x d).\n",
        "        Y_sample: Sample values (n x 1).\n",
        "        gpr: A GaussianProcessRegressor fitted to samples.\n",
        "        xi: Exploitation-exploration trade-off parameter.\n",
        "\n",
        "    Returns:\n",
        "        Expected improvements at points X.\n",
        "    '''\n",
        "    mu, sigma = gpr.predict(X, return_std=True)\n",
        "    mu_sample = gpr.predict(X_sample)\n",
        "\n",
        "    sigma = sigma.reshape(-1, 1)\n",
        "\n",
        "    # Needed for noise-based model,\n",
        "    # otherwise use np.max(Y_sample).\n",
        "    # See also section 2.4 in [...]\n",
        "    mu_sample_opt = np.max(mu_sample)\n",
        "\n",
        "    with np.errstate(divide='warn'):\n",
        "        imp = mu - mu_sample_opt - xi\n",
        "        Z = imp / sigma\n",
        "        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
        "        ei[sigma == 0.0] = 0.0\n",
        "\n",
        "    return ei"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWAbDpY-RKic"
      },
      "source": [
        "We also need a function that proposes the next sampling point by computing the location of the acquisition function maximum. Optimization is restarted `n_restarts` times to avoid local optima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KqLfzFJNRKid"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize import minimize\n",
        "\n",
        "def propose_location(acquisition, X_sample, Y_sample, gpr, bounds, n_restarts=25):\n",
        "    '''\n",
        "    Proposes the next sampling point by optimizing the acquisition function.\n",
        "\n",
        "    Args:\n",
        "        acquisition: Acquisition function.\n",
        "        X_sample: Sample locations (n x d).\n",
        "        Y_sample: Sample values (n x 1).\n",
        "        gpr: A GaussianProcessRegressor fitted to samples.\n",
        "\n",
        "    Returns:\n",
        "        Location of the acquisition function maximum.\n",
        "    '''\n",
        "    dim = X_sample.shape[1]\n",
        "    min_val = 1\n",
        "    min_x = None\n",
        "\n",
        "    def min_obj(X):\n",
        "        # Minimization objective is the negative acquisition function\n",
        "        return -acquisition(X.reshape(-1, dim), X_sample, Y_sample, gpr)\n",
        "\n",
        "    # Find the best optimum by starting from n_restart different random points.\n",
        "    for x0 in np.random.uniform(bounds[:, 0], bounds[:, 1], size=(n_restarts, dim)):\n",
        "        res = minimize(min_obj, x0=x0, bounds=bounds, method='L-BFGS-B')\n",
        "        if res.fun < min_val:\n",
        "            min_val = res.fun\n",
        "            #min_val = res.fun[0]\n",
        "            min_x = res.x\n",
        "\n",
        "    return min_x.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYJ3tjydRKid"
      },
      "source": [
        "Now we have all components needed to run Bayesian optimization with the [algorithm](#Optimization-algorithm) outlined above. The Gaussian process in the following example is configured with a [Matérn kernel](http://scikit-learn.org/stable/modules/gaussian_process.html#matern-kernel) which is a generalization of the squared exponential kernel or RBF kernel. The known noise level is configured with the `alpha` parameter.\n",
        "\n",
        "Bayesian optimization runs for 10 iterations. In each iteration, a row with two plots is produced. The left plot shows the noise-free objective function, the surrogate function which is the GP posterior predictive mean, the 95% confidence interval of the mean and the noisy samples obtained from the objective function so far. The right plot shows the acquisition function. The vertical dashed line in both plots shows the proposed sampling point for the next iteration which corresponds to the maximum of the acquisition function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def distance(p1, p2):\n",
        "    return math.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)\n",
        "def closest(pt, others):\n",
        "    return min(others, key = lambda i: distance(pt, i))"
      ],
      "metadata": {
        "id": "9bQ7g3jYIlgs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import axes3d"
      ],
      "metadata": {
        "id": "khWNlwp-LO0-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install matplotlib=2.2.3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri2p0XGTChFm",
        "outputId": "9bd362f3-0114-4cdf-ff97-c7498fc859ba"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": false,
        "id": "RUpxGcRLRKid"
      },
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import ConstantKernel, Matern\n",
        "from bayesian_optimization_util import plot_approximation, plot_acquisition\n",
        "from sklearn.gaussian_process.kernels import RBF,ConstantKernel as C,RationalQuadratic as RQ,WhiteKernel,ExpSineSquared as Exp,DotProduct as Lin\n",
        "from numpy import exp,arange\n",
        "from pylab import meshgrid,cm,imshow,contour,clabel,colorbar,axis,title,show"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(gpr, prediction, i, X_pool, Y_pool, X_next, X_next_availble):\n",
        "\n",
        "    if i == 0:\n",
        "        prediction = []\n",
        "        # Initialize samples\n",
        "        global X_sample\n",
        "        X_sample = X_init\n",
        "        global Y_sample\n",
        "        Y_sample = Y_init\n",
        "\n",
        "        # Number of iterations\n",
        "        n_iter = 10\n",
        "\n",
        "        plt.figure(figsize=(12, n_iter * 3))\n",
        "        plt.subplots_adjust(hspace=0.4)\n",
        "\n",
        "\n",
        "\n",
        "    # Update Gaussian process with existing samples\n",
        "    gpr.fit(X_sample, Y_sample)\n",
        "\n",
        "\n",
        "    X_next = propose_location(expected_improvement, X_sample, Y_sample, gpr, bounds)\n",
        "    X_next_availble = closest(X_next, X_pool)\n",
        "\n",
        "\n",
        "    # Obtain next closest sample from the avalible sample pool\n",
        "    #Y_next_availble = f(X_next_availble, noise)\n",
        "    t1 = np.argwhere(X_pool[:,0] == X_next_availble[0])\n",
        "    t2 = np.argwhere(X_pool[:,1] == X_next_availble[1])\n",
        "    index = np.intersect1d(t1,t2)\n",
        "    Y_next_availble = Y_pool[index]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Add sample to previous samples\n",
        "    X_sample = np.vstack((X_sample, X_next_availble))\n",
        "    Y_sample = np.vstack((Y_sample, Y_next_availble))\n",
        "\n",
        "\n",
        "    # Reshape X_next\n",
        "    X_next = np.reshape(X_next, (1, 2))\n",
        "\n",
        "\n",
        "    print(\"the next suggestion is {}, predicted to be {}\".format(X_next, gpr.predict(X_next)))\n",
        "    print(\" \")\n",
        "    print(\"Next availble sample: {}\".format(X_next_availble))\n",
        "    prediction.append(float(gpr.predict(X_next)))\n",
        "    print(\" \")\n",
        "    print(\"Predition history: \")\n",
        "    print(prediction)\n",
        "    print(\" \")\n",
        "    print(\"Samples used: \")\n",
        "    print(X_sample)\n",
        "    print(\" \")\n",
        "    print(\"Samples' value used: \")\n",
        "    print(Y_sample)\n",
        "    print(\" \")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Plot 3D pridictions\n",
        "    fig = plt.figure(figsize=(10,6))\n",
        "    ax1 = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    x1 = np.arange(0.9,4.2,0.1)\n",
        "    x2 = np.arange(14,36,0.5)\n",
        "    X1,X2 = np.meshgrid(x1,x2)\n",
        "\n",
        "    test1 = np.reshape(X1,(1452,1))\n",
        "    test2 = np.reshape(X2,(1452,1))\n",
        "    X12 = np.concatenate((test1, test2), axis=1)\n",
        "\n",
        "    Y = gpr.predict(X12)\n",
        "    Y = np.reshape(Y,(44, 33))\n",
        "\n",
        "    mycmap = plt.get_cmap('gist_earth')\n",
        "    ax1.set_title('Iteration {}'.format(i))\n",
        "    surf1 = ax1.plot_surface(X1, X2, Y, cmap=mycmap)\n",
        "    ax1.scatter(X_sample[:-1,0], X_sample[:-1,1], Y_sample[:-1], color = 'black')\n",
        "    ax1.scatter(X_next[0][0], X_next[0][1], Y_sample[-1], color='orange')\n",
        "    ax1.scatter(X_next_availble[0], X_next_availble[1], Y_sample[-1], color='red')\n",
        "    fig.colorbar(surf1, ax=ax1, shrink=0.5, aspect=5)\n",
        "    plt.show()\n",
        "\n",
        "    plot = plt.pcolormesh(X1, X2, Y, cmap='RdBu', shading='auto')\n",
        "\n",
        "    # Plot 2D pridictions\n",
        "    levels = np.arange(97,100,0.01)\n",
        "    cset = plt.contour(X1, X2, Y, cmap='gray')\n",
        "    plt.clabel(cset, inline=True)\n",
        "    plt.plot(X_sample[:,0], X_sample[:,1], 'o', color='black')\n",
        "    plt.plot(X_next[0][0], X_next[0][1], 'o', color='orange');\n",
        "    plt.plot(X_next_availble[0], X_next_availble[1], 'o', color='red')\n",
        "    plt.colorbar(plot)\n",
        "\n",
        "\n",
        "    # Remove used sample\n",
        "    index_to_remove = np.where(np.all(X_pool == X_next_availble,axis=1))\n",
        "    X_pool = np.delete(X_pool, index_to_remove, 0)\n",
        "    Y_pool = np.delete(Y_pool, index_to_remove, 0)\n",
        "\n",
        "\n",
        "\n",
        "    i +=1\n",
        "\n",
        "    return i, prediction, X_pool, Y_pool, X_next, X_next_availble"
      ],
      "metadata": {
        "id": "Z3Juud1HeOJy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize\n",
        "i = 0\n",
        "prediction = []\n",
        "X_next = []\n",
        "X_next_availble = []\n",
        "\n",
        "kernel = 1 * RBF([1,6])\n",
        "gpr = GaussianProcessRegressor(kernel=kernel, random_state=0)\n",
        "\n",
        "#X_all = np.array([[-1.33,-0.8], [-1.33,-0.1], [-1.33,0.59],\n",
        "#\n",
        "#                 [-0.34,-1.5], [-0.34,-0.8], [-0.34,-0.1], [-0.34,0.59], [-0.34,1.29],\n",
        "#\n",
        "#                 [0.6475,-1.5], [0.6475,-0.8], [0.6475,-0.1], [0.6475,0.59], [0.6475,1.29],\n",
        "#\n",
        "#                 [1.6358,-0.8], [1.6358,-0.1], [1.6358,0.59],])\n",
        "#Y_all = np.array([[-1.166], [-1.608], [-2.444],\n",
        " #\n",
        " #                [0.479], [0.789], [0.888], [0.783], [0.838],\n",
        " #\n",
        " #                [-0.375], [-0.097], [0.3615], [0.622], [0.5783],\n",
        " #               [-0.0658], [0.2376], [0.03325]])\n",
        "\n",
        "\n",
        "X_all = np.array([[1,15], [1,20], [1,25], [1,30],[1,35],\n",
        "                  [1.273,27.5],[1.486,20.4],[1.486,34.6],\n",
        "                 [2,15],[2,17.5], [2,20], [2,25],[2,27.5], [2,30], [2,35],\n",
        "                  [2.51,20.4],[2.51,34.6],[2.73,27.5],\n",
        "                  [3,15], [3,20], [3,25], [3,30], [3,35],\n",
        "                  [4,15],[4,20], [4,25], [4,30],[4,35]])\n",
        "Y_all = np.array([[98.08],[98.2565], [97.9], [97.225],[97.03],\n",
        "                  [99.01],[99.76],[99.32],\n",
        "                  [99.585],[99.66], [99.835], [99.915],[99.88], [99.83], [99.875],\n",
        "                  [99.76],[99.88],[99.82],\n",
        "                [98.895], [99.12], [99.49], [99.7], [99.665],\n",
        "                 [98.385],[99.145], [99.39], [99.225],[99.35]])\n",
        "\n",
        "\n",
        "X_pool = X_all\n",
        "Y_pool = Y_all\n",
        "\n",
        "#X_init = np.array([[1,15], [1,35], [4,15], [4,35]])\n",
        "X_init = X_all\n",
        "#Y_init = np.array([[98.08], [97.03], [98.385], [99.35]])\n",
        "Y_init = Y_all\n",
        "\n",
        "#X_init = np.array([[-1.33,-1.5], [-1.33,1.29], [1.6358,-1.5], [1.6358,1.29]])\n",
        "\n",
        "#Y_init = np.array([[-1.3851], [-2.68576], [-1], [0.188]])\n"
      ],
      "metadata": {
        "id": "fzWYyQC9Zgon"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "i, prediction, X_pool, Y_pool, X_next, X_next_availble = predict(gpr, prediction, i, X_pool, Y_pool, X_next, X_next_availble)"
      ],
      "metadata": {
        "id": "dhZAqW30dsM9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}